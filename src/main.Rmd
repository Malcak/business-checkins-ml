---
title: "Taller Business Checkins"
author: "Manuel Alejandro Castaño Jaramillo, davila, yajaira"
date: "4/12/2020"
output:
  html_notebook:
    toc: true
    toc_float: true
---

# Introducción
Analizaremos los datos proveidos por la plataforma **Yelp** sobre el número de entradas a restaurantes de Pittsburgh para entrenar un modelo de aprendizaje automático que predice el nivel de carga de trabajo de cualquier restaurante de pittsburgh en un día y hora específicos.

## Importando Librerías y Datos
```{r}
## librerías

# librerías para crear visualizaciones
library(ggplot2)

library(dplyr)
library(pROC)
library(tidyverse)
library(caret)

# librería para los modelos de aprendizaje automático
library(naivebayes)
library(randomForest)
library(rpart)
library(rpart.plot)

# importing business checkin data from yelp
data = read.csv("../data/business_checkin.csv", header = TRUE, sep = ",")

```

# Descripción de los Datos
El conjunto de datos cuenta con **16800** registros donde encontraremos ciertas características de algunos negocios en cada hora de cada día de la semana, de estos datos tan solo **1512** son registros de negocios con la categoría de restaurante y en las horas en que se encontraban abiertos.

Los datos cuentan con las siguientes variables:

* **rownumber**: El índice del registro en la base de datos.
* **business_id**: El identificador del negocio.
* **city**: La ciudad en la que se encuentra el negocio.
* **stars**: Las estrellas con las que contaba el negocio al momento de hacer la medición.
* **review_count**: El número de reviews con las que contaba el negocio al momento de hacer la medición.
* **is_open**: Si el negocio estaba abierto en el momento que se hizo la medición.
* **category**: La categoría con la cual se identifica el negocio.
* **day_time**: El día de la semana y la hora en que se hizo la medición.
* **week_way**: El día de la semana en que se hizo la medición.
* **hourofday**: La hora en que se hizo la medición.
* **checkins**: La cantidad de entradas al negocio en el momento que se hizo la medición.

```{r}
# filtrando el datset original por la categoría restaurante y la ciudad de Pittsburgh
data_restaurants <- subset(data, category=="Restaurants" & is_open==TRUE)
data_restaurants <- subset(data_restaurants, city=="Pittsburgh")

head(data_restaurants)
```

## Tipo de variables
```{r}
# visualizar los tipos de las variables y ejemplo de los valores
glimpse(data_restaurants)
```
En la tabla anterior puede verse el tipo de cada variable, así como un ejemplo de los valores que toma. La variable week_day y hourofday se convierten a tipo factor
```{r}
# convitiendo los días de las semana y las horas del día en factores
data_restaurants$week_day <- as.factor(data_restaurants$week_day)
data_restaurants$hourofday <- as.factor(data_restaurants$hourofday)
```

## Número de observaciones y valores ausentes

### Número de observaciones
```{r}
nrow(data_restaurants)
```
# verificar si existen filas imcompletas
```{r}
any(!complete.cases(data_restaurants))
```

## Limpiando las Variables no Deseadas

Se eliminarán la siguientes variables de dataset.

* **rownumber**: Porque es el índice de la fila y no tiene nada que ver con el problema.
* **business_id**: Porque se busca que el modelo prediga la carga laboral en general de los restaurantes de Pittsburgh y no de cada restaurante de forma específica, además si se buscara esto se contaría con muy pocos datos por cada negocio.
* **city**: Porque la única cuidad tratada en el problema es Pittsburgh
* **is_open**: Porque en el único momento enq ue un restaurante debería tener entradas es en el momento que esté abierto, el resto se consideraron como errores en el momento de la medición de los datos.
* **category**: Porque la única categoría tratada en el problema son los restaurantes.
* **day_time**: Porque este es un dato redundante, su información ya la aportan las variables de "**week_day**" y "**hourofday**".

```{r}
# limpiando variables innecesarias
data_restaurants$ï..rownumber <- NULL
data_restaurants$day_time <- NULL
data_restaurants$business_id <- NULL
data_restaurants$is_open <- NULL
data_restaurants$city <- NULL
data_restaurants$category <- NULL
head(data_restaurants)
```

## Transformando Checkins a factores

Tomaremos los casos donde se presentan de **0** a **4** checkins como casos donde hay baja carga laboral, de **5** a **9** como casos donde hay carga laboral media y de **10** en adelante como casos donde hay carga laboral alta
```{r}
# se crea la columna checkins_cat con la categoría la que pertenece según su número de checkins
data_restaurants$checkins_cat <- cut(data_restaurants$checkins, breaks = c(0, 5, 10, Inf),
                  labels = c("baja", "media", "alta"),
                  right = FALSE)
# se reordenan las columnas del dataset
data_restaurants <- data.frame(data_restaurants %>% select(stars,review_count, hourofday, week_day, checkins, checkins_cat))

# se elimina la variables númerica de los checkins
data_restaurants$checkins <- NULL
```

## Visualización del Comportamiento de los Datos

### Distribución de cada clase de checkins
```{r}
ggplot(data = data_restaurants, aes(x = checkins_cat, y = ..count.., fill = checkins_cat)) +
  geom_bar() +
  scale_fill_manual(values = c("yellow2", "orange2", "red2")) +
  labs(title = "Carga de trabajo") +
  theme_bw() +
  theme(legend.position = "bottom")
```
## proporción de las clases
```{r}
# frecuencia de cada clase
table(data_restaurants$checkins_cat)
```

```{r}
# proporción de cada clase
prop.table(table(data_restaurants$checkins_cat)) %>% round(digits = 2)
```

### Gráfico del Número de Checkins por cada Día de la Semana
```{r}
ggplot(
  data=data_restaurants,
  aes(x=week_day, y=checkins_cat)
) + geom_bar(stat="identity")
```

### Gráfico de Características
```{r}
featurePlot(x = data_restaurants[, 1:4], 
            y = data_restaurants$checkins_cat, 
            plot = "pairs",
            auto.key = list(columns = 3))
```

## Resampling
Debido a que las clases están altamente desbalanceadas se buscará nivelar las clases con métodos de remuestreo, se tuvieron en cuenta métodos de undersampling como el Random Undersampling pero se descartó ya que la clase minoritaria cuenta con únicamente 24 registros, esto causaba que se perdiera demasiada información.
De métodos de oversampling se provó con SMOTE y Random Oversampling y se dejó únicamente el Random Oversampling ya que fue el que dio el mejor rendimiento.
```{r}
set.seed(1000)
# Random Oversampling
up_dataset <- upSample(x = data_restaurants[, -ncol(data_restaurants)],
                       y = data_restaurants$checkins_cat)
up_dataset <- rename(up_dataset, c("checkins_cat" = "Class"))

# frecuencia de cada clase después de ser balanceadas
table(up_dataset$checkins_cat)
```
Se revolvieron los registros.
```{r}
# shuffle the dataframe
up_dataset <- up_dataset[sample(nrow(up_dataset)),]
```

# División de los datos en Entrenamiento y Prueba
```{r}
# Se crean los índices de las observaciones de entrenamiento
train <- createDataPartition(y = up_dataset$checkins_cat, p = 0.8, list = FALSE, times = 1)
# Se particiona el dataset
data_train <- up_dataset[train, ]
data_test  <- up_dataset[-train, ]
nrow(data_train) 
nrow(data_test)
```
Evaluar la capacidad predictiva de un modelo consiste en comprobar cómo de próximas son sus predicciones a los verdaderos valores de la variable respuesta. Para poder cuantificar de forma correcta este error, se necesita disponer de un conjunto de observaciones, de las que se conozca la variable respuesta, pero que el modelo no haya “visto”, es decir, que no hayan participado en su ajuste. Con esta finalidad, se dividen los datos disponibles en un conjunto de entrenamiento y un conjunto de prueba. En este caso el conjunto de entrenamiento contará con el **80%** de los datos mientras que el de pruebas contará con **20%**.


# Creación de los modelos predictivos

## Naive Bayes
Para el caso del entrenaiento con Naive Bayes no se modificará ninguno de sus hiperparámetros.
```{r}
modelo_naivebayes <- naive_bayes(formula = checkins_cat ~ .,  data = data_train)
```
Posterior al entremiento del modelo se realizan las pruebas con el conjunto de puebas que se particionó anteriormente.
```{r}
# se lleva a cabo la etapa de pruebas para determinar la capacidad de predicción del modelo
predictions_nb <- predict(modelo_naivebayes, data_test)
head(predictions_nb, 25)
```

### Métricas del modelo con Random Forest
```{r}
# métricas de evaluación
confusion<-confusionMatrix(predictions_nb, data_test[["checkins_cat"]])
confusion
confusion[["byClass"]]
```

### Área bajo la curva ROC
```{r}
multiclass.roc(as.numeric(predictions_nb), as.numeric(data_test[["checkins_cat"]]))
```

## Decision Tree
Para el caso del Árbol de decisión tampoco se modificarán los hiperparámetros por defecto.
```{r}
modelo_dt <- rpart(formula = checkins_cat ~ ., data = data_train)
```
visualizamos el árbol generado por el método.
```{r}
rpart.plot(modelo_dt)
```

### Métricas del modelo con Árbol de Decisión
Posterior al entremiento del modelo se realizan las pruebas con el conjunto de puebas que se particionó anteriormente.
```{r}
predictions_dt <- predict(modelo_dt, newdata = data_test, type = "class")
```
```{r}
confusionMatrix(predictions_dt, data_test[["checkins_cat"]])
```

### Área bajo la curva ROC
```{r}
multiclass.roc(as.numeric(predictions_dt), as.numeric(data_test[, "checkins_cat"]))
```

## Random Forest
Para el modelo creado a través de Random Forest si se modificará algunos de los hiperparámetros ya que anteriormente se realizó una validación de hiperparámetros donde se evaluó como rinde el modelo segón diferentes valores de los siguientes parametros:
* **min.node.size**: tamaño mínimo que tiene que tener un nodo para poder ser dividido.
* **splitrule**: criterio de división, el que obtuvo el mejor rendimiento fue Gini Impurity por lo que no se modificará ya que es el criterio por defecto que utiliza el modelo.

```{r}
modelo_randforest <- randomForest(formula = checkins_cat ~ . ,
                                  data = data_train,
                                  importance = TRUE,
                                  min.node.size = 10,
                                  ntree = 500)
print(modelo_randforest)
```
Podemos ver en la siguiente tabla el resultado de evaluar el modelo con el conjunto de pruebas.
```{r}
predictions <- predict(modelo_randforest, data_test)
table(real = data_test[, "checkins_cat"], prediction = predictions)
```
En la tabla inferior podemos ver las métricas que posteriormente pasaremos a comparar entre los diferentes modelos.

### Métricas del modelo con Random Forest
```{r}
confusionMatrix(predictions, as.factor(data_test[, "checkins_cat"]), positive = "alta", mode="prec_recall")

```

### Área bajo la curva ROC
```{r}
multiclass.roc(as.numeric(predictions), as.numeric(data_test[, "checkins_cat"]))
```
En la gráfica infeior podemos ver como varió el error según el número de árboles, como se puede observar a partir de los 200 arboles no parecen haber diferencias claras.
```{r}
plot(modelo_randforest)
```

```{r}
plot (randomForest::margin(modelo_randforest))
```

### Importancia de las características
```{r}
importance <- as.data.frame(modelo_randforest$importance)
varImpPlot(modelo_randforest)
```

# Comparación de lo Modelos

# Posibles mejoras


# Referencias
https://www.cienciadedatos.net/documentos/41_machine_learning_con_r_y_caret#Modelos
https://www.cienciadedatos.net/documentos/33_arboles_decision_random_forest_gradient_boosting_c50#Random_Forest


